{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Shape of Uncertainty and Hypothesis Testing\n",
    "\n",
    "**An Interactive Exploration**\n",
    "\n",
    "*Developed for students at Kuchinda College, Sambalpur University*\n",
    "\n",
    "---\n",
    "\n",
    "## Core Question\n",
    "\n",
    "**How do we decide if an observation is \"unusual\" or \"expected\"?**\n",
    "\n",
    "The answer lies in understanding the **shape of uncertainty** - the probability distribution that describes what we expect to see under different scenarios.\n",
    "\n",
    "In this notebook, you'll:\n",
    "1. See how different distributions create different \"shapes of uncertainty\"\n",
    "2. Understand how these shapes define what's \"rare\" vs \"common\"\n",
    "3. Explore how changing parameters affects hypothesis testing decisions\n",
    "4. Apply these concepts to real biological scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from ipywidgets import interact, FloatSlider, IntSlider, Dropdown, fixed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: The Shape of Uncertainty - Coin Flipping Example\n",
    "\n",
    "Let's start with the simplest case: flipping a coin multiple times.\n",
    "\n",
    "**Question:** If we flip a coin 10 times, how many heads do we expect?\n",
    "\n",
    "The answer depends on whether the coin is fair or biased. The **shape of uncertainty** shows us all possible outcomes and their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_binomial_hypothesis(n_flips=10, true_p=0.5, observed_heads=7, null_p=0.5):\n",
    "    \"\"\"\n",
    "    Visualize how the shape of uncertainty helps in hypothesis testing.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_flips: number of coin flips\n",
    "    - true_p: true probability of heads (what nature actually is)\n",
    "    - observed_heads: what we actually observed\n",
    "    - null_p: probability under null hypothesis (usually 0.5 for fair coin)\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Possible outcomes\n",
    "    x = np.arange(0, n_flips + 1)\n",
    "    \n",
    "    # Left plot: Distribution under NULL hypothesis\n",
    "    null_probs = stats.binom.pmf(x, n_flips, null_p)\n",
    "    axes[0].bar(x, null_probs, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    \n",
    "    # Highlight the observed value\n",
    "    axes[0].bar(observed_heads, stats.binom.pmf(observed_heads, n_flips, null_p), \n",
    "                color='red', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Calculate p-value (two-tailed)\n",
    "    p_value = stats.binomtest(observed_heads, n_flips, null_p, alternative='two-sided').pvalue\n",
    "    \n",
    "    # Shade the rejection region (alpha = 0.05)\n",
    "    critical_low = stats.binom.ppf(0.025, n_flips, null_p)\n",
    "    critical_high = stats.binom.ppf(0.975, n_flips, null_p)\n",
    "    \n",
    "    for i in x:\n",
    "        if i <= critical_low or i >= critical_high:\n",
    "            axes[0].bar(i, null_probs[i], alpha=0.3, color='orange', edgecolor='black')\n",
    "    \n",
    "    axes[0].set_xlabel('Number of Heads', fontsize=12)\n",
    "    axes[0].set_ylabel('Probability', fontsize=12)\n",
    "    axes[0].set_title(f'Shape of Uncertainty under NULL (p={null_p})\\nObserved: {observed_heads} heads', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].axvline(observed_heads, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Add text annotation\n",
    "    decision = \"REJECT NULL\" if p_value < 0.05 else \"FAIL TO REJECT NULL\"\n",
    "    color = 'red' if p_value < 0.05 else 'green'\n",
    "    axes[0].text(0.5, 0.95, f'p-value = {p_value:.4f}\\n{decision}', \n",
    "                transform=axes[0].transAxes, fontsize=11, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor=color, alpha=0.3))\n",
    "    \n",
    "    # Right plot: Distribution under TRUE parameter (what nature actually is)\n",
    "    true_probs = stats.binom.pmf(x, n_flips, true_p)\n",
    "    axes[1].bar(x, true_probs, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1].bar(observed_heads, stats.binom.pmf(observed_heads, n_flips, true_p), \n",
    "                color='red', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    axes[1].set_xlabel('Number of Heads', fontsize=12)\n",
    "    axes[1].set_ylabel('Probability', fontsize=12)\n",
    "    axes[1].set_title(f'Shape of Uncertainty under TRUE (p={true_p})\\nObserved: {observed_heads} heads', \n",
    "                     fontsize=13, fontweight='bold')\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].axvline(observed_heads, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Calculate probability of observing this under true distribution\n",
    "    prob_under_true = stats.binom.pmf(observed_heads, n_flips, true_p)\n",
    "    axes[1].text(0.5, 0.95, f'P(observe {observed_heads}|true p={true_p}) = {prob_under_true:.4f}', \n",
    "                transform=axes[1].transAxes, fontsize=11, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print interpretation\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INTERPRETATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nYou flipped a coin {n_flips} times and got {observed_heads} heads.\\n\")\n",
    "    print(f\"NULL HYPOTHESIS: The coin is fair (p = {null_p})\")\n",
    "    print(f\"ALTERNATIVE: The coin is NOT fair (p \u2260 {null_p})\\n\")\n",
    "    print(f\"Under the null hypothesis, the probability of getting {observed_heads} or more extreme is {p_value:.4f}\")\n",
    "    print(f\"\\nDecision (\u03b1 = 0.05): {decision}\\n\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"\u2717 The observed result ({observed_heads} heads) falls in the REJECTION REGION (shaded orange).\")\n",
    "        print(f\"  This outcome is too rare under the null hypothesis to be explained by chance alone.\")\n",
    "        print(f\"  We have evidence that the coin is NOT fair.\\n\")\n",
    "    else:\n",
    "        print(f\"\u2713 The observed result ({observed_heads} heads) is CONSISTENT with the null hypothesis.\")\n",
    "        print(f\"  This outcome is reasonably common under a fair coin.\")\n",
    "        print(f\"  We don't have sufficient evidence to say the coin is biased.\\n\")\n",
    "    \n",
    "    print(f\"The TRUE probability is p = {true_p} (but in real experiments, we don't know this!)\")\n",
    "    print(f\"Under the true distribution, observing {observed_heads} heads has probability {prob_under_true:.4f}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Exploration: Play with the parameters!\n",
    "\n",
    "**Instructions:**\n",
    "- `n_flips`: How many times to flip the coin\n",
    "- `true_p`: The ACTUAL probability of heads (what nature really is, but unknown to us)\n",
    "- `observed_heads`: What we actually observed in our experiment\n",
    "- `null_p`: What we assume under the null hypothesis (usually 0.5 for fair coin)\n",
    "\n",
    "**Try these scenarios:**\n",
    "1. Set true_p = 0.5 (fair coin), observed_heads = 5. See how it looks \"expected\"\n",
    "2. Set true_p = 0.5, observed_heads = 9. See how it becomes \"unusual\"\n",
    "3. Set true_p = 0.7 (biased coin), observed_heads = 7. Even though coin IS biased, we might fail to detect it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_binomial_hypothesis,\n",
    "         n_flips=IntSlider(min=5, max=50, step=5, value=10, description='n_flips:'),\n",
    "         true_p=FloatSlider(min=0.1, max=0.9, step=0.1, value=0.5, description='true_p:'),\n",
    "         observed_heads=IntSlider(min=0, max=50, step=1, value=7, description='observed:'),\n",
    "         null_p=fixed(0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Comparing Two Groups - The t-test\n",
    "\n",
    "Now let's move to a more realistic biological scenario:\n",
    "\n",
    "**Scenario:** You're studying earthworm body weight in two sites:\n",
    "- **Site A:** Clean agricultural land (control)\n",
    "- **Site B:** Near coal mining area (potentially contaminated)\n",
    "\n",
    "**Question:** Is there a significant difference in body weight?\n",
    "\n",
    "The **shape of uncertainty** here is the sampling distribution of the difference in means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ttest_hypothesis(n_per_group=20, mean_diff=0.5, std_dev=1.0, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Visualize t-test hypothesis testing with the shape of uncertainty.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_per_group: sample size per group\n",
    "    - mean_diff: true difference in means (Site B - Site A)\n",
    "    - std_dev: standard deviation (assumed equal for both groups)\n",
    "    - alpha: significance level\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate data\n",
    "    np.random.seed(42)\n",
    "    control = np.random.normal(loc=5.0, scale=std_dev, size=n_per_group)  # Site A (clean)\n",
    "    treatment = np.random.normal(loc=5.0 + mean_diff, scale=std_dev, size=n_per_group)  # Site B (contaminated)\n",
    "    \n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(treatment, control)\n",
    "    \n",
    "    # Calculate degrees of freedom\n",
    "    df = 2 * n_per_group - 2\n",
    "    \n",
    "    # Critical value\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, df)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Raw data\n",
    "    axes[0, 0].scatter(np.ones(n_per_group) + np.random.normal(0, 0.05, n_per_group), \n",
    "                      control, alpha=0.6, s=100, label='Site A (Control)', color='blue')\n",
    "    axes[0, 0].scatter(2 * np.ones(n_per_group) + np.random.normal(0, 0.05, n_per_group), \n",
    "                      treatment, alpha=0.6, s=100, label='Site B (Mining)', color='orange')\n",
    "    \n",
    "    axes[0, 0].hlines(control.mean(), 0.7, 1.3, colors='blue', linewidth=3, label=f'Mean A: {control.mean():.2f}')\n",
    "    axes[0, 0].hlines(treatment.mean(), 1.7, 2.3, colors='orange', linewidth=3, label=f'Mean B: {treatment.mean():.2f}')\n",
    "    \n",
    "    axes[0, 0].set_xlim(0.5, 2.5)\n",
    "    axes[0, 0].set_xticks([1, 2])\n",
    "    axes[0, 0].set_xticklabels(['Site A\\n(Clean)', 'Site B\\n(Mining)'])\n",
    "    axes[0, 0].set_ylabel('Earthworm Body Weight (g)', fontsize=11)\n",
    "    axes[0, 0].set_title('Raw Data: Earthworm Weights at Two Sites', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].legend(loc='upper left')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Distribution of each group\n",
    "    axes[0, 1].hist(control, bins=15, alpha=0.5, label='Site A', color='blue', edgecolor='black')\n",
    "    axes[0, 1].hist(treatment, bins=15, alpha=0.5, label='Site B', color='orange', edgecolor='black')\n",
    "    axes[0, 1].axvline(control.mean(), color='blue', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].axvline(treatment.mean(), color='orange', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Body Weight (g)', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[0, 1].set_title('Distribution of Weights\\n(The variability within each group)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Sampling distribution under NULL (difference = 0)\n",
    "    x_range = np.linspace(-4, 4, 1000)\n",
    "    null_dist = stats.t.pdf(x_range, df)\n",
    "    \n",
    "    axes[1, 0].plot(x_range, null_dist, 'b-', linewidth=2, label='Null Distribution')\n",
    "    axes[1, 0].fill_between(x_range, null_dist, where=(x_range < -t_critical), alpha=0.3, color='red', label='Rejection Region')\n",
    "    axes[1, 0].fill_between(x_range, null_dist, where=(x_range > t_critical), alpha=0.3, color='red')\n",
    "    axes[1, 0].axvline(t_stat, color='darkred', linestyle='--', linewidth=2.5, label=f'Observed t = {t_stat:.2f}')\n",
    "    axes[1, 0].axvline(-t_critical, color='red', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "    axes[1, 0].axvline(t_critical, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label=f'Critical t = \u00b1{t_critical:.2f}')\n",
    "    \n",
    "    axes[1, 0].set_xlabel('t-statistic', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('Probability Density', fontsize=11)\n",
    "    axes[1, 0].set_title(f'Shape of Uncertainty under NULL\\n(No difference between sites)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].legend(loc='upper right', fontsize=9)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Effect size and power visualization\n",
    "    observed_diff = treatment.mean() - control.mean()\n",
    "    pooled_std = np.sqrt((control.var() + treatment.var()) / 2)\n",
    "    cohen_d = observed_diff / pooled_std\n",
    "    \n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    decision = \"REJECT NULL\" if p_value < alpha else \"FAIL TO REJECT NULL\"\n",
    "    color = 'red' if p_value < alpha else 'green'\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "    HYPOTHESIS TEST SUMMARY\n",
    "    {'='*50}\n",
    "    \n",
    "    Sample sizes: n\u2081 = n\u2082 = {n_per_group}\n",
    "    \n",
    "    Site A mean: {control.mean():.3f} g\n",
    "    Site B mean: {treatment.mean():.3f} g\n",
    "    Observed difference: {observed_diff:.3f} g\n",
    "    \n",
    "    Standard deviations: {std_dev:.2f} g (assumed equal)\n",
    "    Pooled SD: {pooled_std:.3f} g\n",
    "    \n",
    "    t-statistic: {t_stat:.3f}\n",
    "    Degrees of freedom: {df}\n",
    "    p-value: {p_value:.4f}\n",
    "    \n",
    "    Significance level \u03b1: {alpha}\n",
    "    Critical t: \u00b1{t_critical:.3f}\n",
    "    \n",
    "    Cohen's d (effect size): {cohen_d:.3f}\n",
    "    \n",
    "    DECISION: {decision}\n",
    "    \n",
    "    {'='*50}\n",
    "    \n",
    "    INTERPRETATION:\n",
    "    \"\"\"\n",
    "    \n",
    "    if p_value < alpha:\n",
    "        summary_text += f\"\"\"\n",
    "    \u2717 The observed t-statistic ({t_stat:.2f}) falls in the\n",
    "      REJECTION REGION (|t| > {t_critical:.2f}).\n",
    "      \n",
    "    \u2717 p-value ({p_value:.4f}) < \u03b1 ({alpha})\n",
    "    \n",
    "    \u2717 CONCLUSION: There IS a statistically significant\n",
    "      difference in earthworm body weights between\n",
    "      the clean site and mining site.\n",
    "      \n",
    "    Mining contamination appears to affect earthworm\n",
    "    body weight.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        summary_text += f\"\"\"\n",
    "    \u2713 The observed t-statistic ({t_stat:.2f}) falls within\n",
    "      the ACCEPTANCE REGION (|t| \u2264 {t_critical:.2f}).\n",
    "      \n",
    "    \u2713 p-value ({p_value:.4f}) \u2265 \u03b1 ({alpha})\n",
    "    \n",
    "    \u2713 CONCLUSION: There is NO statistically significant\n",
    "      difference in earthworm body weights between\n",
    "      the clean site and mining site.\n",
    "      \n",
    "    The observed difference could be due to random\n",
    "    sampling variation.\n",
    "        \"\"\"\n",
    "    \n",
    "    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=10, family='monospace',\n",
    "                   verticalalignment='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor=color, alpha=0.2))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Exploration: Earthworm Body Weight Study\n",
    "\n",
    "**Instructions:**\n",
    "- `n_per_group`: Number of earthworms sampled from each site\n",
    "- `mean_diff`: TRUE difference in mean weights (Site B - Site A) - unknown to us in real study!\n",
    "- `std_dev`: Biological variability (how much weights vary within each site)\n",
    "- `alpha`: Significance level (usually 0.05)\n",
    "\n",
    "**Explore these scenarios:**\n",
    "1. **No effect:** mean_diff = 0, n_per_group = 20. See how often we correctly fail to reject.\n",
    "2. **Small effect:** mean_diff = 0.3, n_per_group = 20. Might not detect it!\n",
    "3. **Increase sample size:** mean_diff = 0.3, n_per_group = 50. Better chance of detection!\n",
    "4. **High variability:** mean_diff = 0.5, std_dev = 2.0. Harder to detect even real effects.\n",
    "5. **Large effect:** mean_diff = 1.5, n_per_group = 20. Easy to detect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_ttest_hypothesis,\n",
    "         n_per_group=IntSlider(min=10, max=100, step=10, value=20, description='n per group:'),\n",
    "         mean_diff=FloatSlider(min=0, max=2.0, step=0.1, value=0.5, description='true diff:'),\n",
    "         std_dev=FloatSlider(min=0.5, max=3.0, step=0.5, value=1.0, description='std dev:'),\n",
    "         alpha=FloatSlider(min=0.01, max=0.10, step=0.01, value=0.05, description='alpha:'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The Shape Changes Everything - Different Distributions\n",
    "\n",
    "Different types of data follow different probability distributions. The **shape** determines:\n",
    "- What's considered \"rare\" vs \"common\"\n",
    "- Where rejection regions fall\n",
    "- The power to detect effects\n",
    "\n",
    "Let's compare three common distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(df_param=5):\n",
    "    \"\"\"\n",
    "    Compare Normal, t-distribution, and Chi-square distributions.\n",
    "    Shows how different shapes affect what we consider \"extreme\".\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    \n",
    "    # Normal distribution\n",
    "    normal = stats.norm.pdf(x, 0, 1)\n",
    "    axes[0].plot(x, normal, 'b-', linewidth=2, label='Normal(0,1)')\n",
    "    axes[0].fill_between(x, normal, where=(np.abs(x) > 1.96), alpha=0.3, color='red', \n",
    "                         label='Rejection region\\n(\u03b1=0.05, two-tailed)')\n",
    "    axes[0].axvline(-1.96, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    axes[0].axvline(1.96, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    axes[0].set_xlabel('Value', fontsize=11)\n",
    "    axes[0].set_ylabel('Probability Density', fontsize=11)\n",
    "    axes[0].set_title('Normal Distribution\\n(Large samples, many variables)', fontsize=12, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].text(0, -0.05, '95% of data\\nwithin \u00b11.96 SD', ha='center', transform=axes[0].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "    \n",
    "    # t-distribution\n",
    "    t_dist = stats.t.pdf(x, df_param)\n",
    "    normal_compare = stats.norm.pdf(x, 0, 1)\n",
    "    t_critical = stats.t.ppf(0.975, df_param)\n",
    "    \n",
    "    axes[1].plot(x, t_dist, 'g-', linewidth=2, label=f't-distribution (df={df_param})')\n",
    "    axes[1].plot(x, normal_compare, 'b--', linewidth=1.5, alpha=0.5, label='Normal (for comparison)')\n",
    "    axes[1].fill_between(x, t_dist, where=(np.abs(x) > t_critical), alpha=0.3, color='red',\n",
    "                        label=f'Rejection region\\n(\u03b1=0.05, critical t=\u00b1{t_critical:.2f})')\n",
    "    axes[1].axvline(-t_critical, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    axes[1].axvline(t_critical, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    axes[1].set_xlabel('Value', fontsize=11)\n",
    "    axes[1].set_ylabel('Probability Density', fontsize=11)\n",
    "    axes[1].set_title('t-Distribution\\n(Small samples, unknown variance)', fontsize=12, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].text(0, -0.05, 'Fatter tails\u2192\\nmore extreme values\\nthan Normal', ha='center', \n",
    "                transform=axes[1].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "    \n",
    "    # Chi-square distribution\n",
    "    x_chi = np.linspace(0, 20, 1000)\n",
    "    chi_sq = stats.chi2.pdf(x_chi, df_param)\n",
    "    chi_critical = stats.chi2.ppf(0.95, df_param)\n",
    "    \n",
    "    axes[2].plot(x_chi, chi_sq, 'orange', linewidth=2, label=f'\u03c7\u00b2 (df={df_param})')\n",
    "    axes[2].fill_between(x_chi, chi_sq, where=(x_chi > chi_critical), alpha=0.3, color='red',\n",
    "                        label=f'Rejection region\\n(\u03b1=0.05, critical \u03c7\u00b2={chi_critical:.2f})')\n",
    "    axes[2].axvline(chi_critical, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    axes[2].set_xlabel('Value', fontsize=11)\n",
    "    axes[2].set_ylabel('Probability Density', fontsize=11)\n",
    "    axes[2].set_title('Chi-Square Distribution\\n(Variance tests, goodness-of-fit)', fontsize=12, fontweight='bold')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].text(0.5, -0.05, 'Skewed, only positive\u2192\\nused for variance,\\ncategorical data', \n",
    "                ha='center', transform=axes[2].transAxes,\n",
    "                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY INSIGHTS: How Shape Affects Hypothesis Testing\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n1. NORMAL DISTRIBUTION:\")\n",
    "    print(\"   - Symmetric, bell-shaped\")\n",
    "    print(\"   - Extreme values (>\u00b11.96 SD) are very rare (5% total)\")\n",
    "    print(\"   - Used when: Large samples, continuous data, symmetric variation\\n\")\n",
    "    \n",
    "    print(\"2. t-DISTRIBUTION:\")\n",
    "    print(\"   - Symmetric but FATTER TAILS than normal\")\n",
    "    print(f\"   - With df={df_param}, critical value is \u00b1{t_critical:.2f} (vs \u00b11.96 for normal)\")\n",
    "    print(\"   - Extreme values are MORE COMMON than in normal distribution\")\n",
    "    print(\"   - Used when: Small samples, estimating population variance from sample\\n\")\n",
    "    \n",
    "    print(\"3. CHI-SQUARE DISTRIBUTION:\")\n",
    "    print(\"   - SKEWED (not symmetric), only positive values\")\n",
    "    print(f\"   - With df={df_param}, critical value (95th percentile) is {chi_critical:.2f}\")\n",
    "    print(\"   - Shape changes dramatically with degrees of freedom\")\n",
    "    print(\"   - Used when: Testing variances, categorical data, goodness-of-fit\\n\")\n",
    "    \n",
    "    print(\"BOTTOM LINE:\")\n",
    "    print(\"The SHAPE determines what counts as 'rare' or 'extreme'.\")\n",
    "    print(\"Using the wrong shape gives wrong p-values and wrong conclusions!\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Comparison: How Does Sample Size (df) Affect the Shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(compare_distributions,\n",
    "         df_param=IntSlider(min=2, max=30, step=1, value=5, \n",
    "                           description='Degrees of Freedom:'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Real Data Example - Gene Expression in Contaminated Sites\n",
    "\n",
    "Let's apply everything to a realistic genomics scenario.\n",
    "\n",
    "**Scenario:** You measured stress gene expression in earthworms from mining vs. control sites.\n",
    "Gene expression data is often **log-normally distributed** (skewed), not normal!\n",
    "\n",
    "This shows why understanding the shape is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_expression_example(n_sample=30, fold_change=2.0, cv=0.5, transform='log'):\n",
    "    \"\"\"\n",
    "    Simulate gene expression data and show effect of transformation.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_sample: sample size per group\n",
    "    - fold_change: multiplicative effect of contamination\n",
    "    - cv: coefficient of variation (biological noise)\n",
    "    - transform: 'none' or 'log' transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate log-normal data (realistic for gene expression)\n",
    "    baseline_mean = 100  # baseline expression level\n",
    "    baseline_sd = baseline_mean * cv\n",
    "    \n",
    "    control = np.random.lognormal(mean=np.log(baseline_mean), sigma=cv, size=n_sample)\n",
    "    treatment = np.random.lognormal(mean=np.log(baseline_mean * fold_change), sigma=cv, size=n_sample)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    \n",
    "    if transform == 'log':\n",
    "        control_transformed = np.log2(control)\n",
    "        treatment_transformed = np.log2(treatment)\n",
    "        ylabel = 'log\u2082(Expression)'\n",
    "    else:\n",
    "        control_transformed = control\n",
    "        treatment_transformed = treatment\n",
    "        ylabel = 'Raw Expression'\n",
    "    \n",
    "    # Row 1: Original scale\n",
    "    # Plot 1: Raw data points\n",
    "    axes[0, 0].scatter(np.ones(n_sample) + np.random.normal(0, 0.05, n_sample), \n",
    "                      control, alpha=0.6, s=80, label='Control', color='blue')\n",
    "    axes[0, 0].scatter(2 * np.ones(n_sample) + np.random.normal(0, 0.05, n_sample), \n",
    "                      treatment, alpha=0.6, s=80, label='Mining Site', color='red')\n",
    "    axes[0, 0].hlines(control.mean(), 0.7, 1.3, colors='blue', linewidth=3)\n",
    "    axes[0, 0].hlines(treatment.mean(), 1.7, 2.3, colors='red', linewidth=3)\n",
    "    axes[0, 0].set_xlim(0.5, 2.5)\n",
    "    axes[0, 0].set_xticks([1, 2])\n",
    "    axes[0, 0].set_xticklabels(['Control', 'Mining'])\n",
    "    axes[0, 0].set_ylabel('Raw Expression Level', fontsize=11)\n",
    "    axes[0, 0].set_title('Original Data\\n(Log-normal distribution)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Histogram of raw data\n",
    "    axes[0, 1].hist(control, bins=20, alpha=0.5, color='blue', edgecolor='black', label='Control')\n",
    "    axes[0, 1].hist(treatment, bins=20, alpha=0.5, color='red', edgecolor='black', label='Mining')\n",
    "    axes[0, 1].axvline(control.mean(), color='blue', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].axvline(treatment.mean(), color='red', linestyle='--', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Raw Expression', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[0, 1].set_title('Distribution Shape\\n(SKEWED - violates t-test assumption)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: t-test on raw data\n",
    "    t_raw, p_raw = stats.ttest_ind(treatment, control)\n",
    "    axes[0, 2].axis('off')\n",
    "    result_text_raw = f\"\"\"\n",
    "    T-TEST ON RAW DATA\n",
    "    {'='*40}\n",
    "    \n",
    "    Control mean: {control.mean():.2f}\n",
    "    Mining mean: {treatment.mean():.2f}\n",
    "    \n",
    "    t-statistic: {t_raw:.3f}\n",
    "    p-value: {p_raw:.4f}\n",
    "    \n",
    "    Decision: {'REJECT' if p_raw < 0.05 else 'FAIL TO REJECT'}\n",
    "    \n",
    "    \u26a0\ufe0f  WARNING: Data is skewed!\n",
    "    t-test assumes normality.\n",
    "    This p-value may be unreliable.\n",
    "    \n",
    "    {'='*40}\n",
    "    \"\"\"\n",
    "    axes[0, 2].text(0.1, 0.5, result_text_raw, fontsize=10, family='monospace',\n",
    "                   verticalalignment='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor='orange', alpha=0.3))\n",
    "    \n",
    "    # Row 2: After log transformation\n",
    "    # Plot 4: Transformed data\n",
    "    axes[1, 0].scatter(np.ones(n_sample) + np.random.normal(0, 0.05, n_sample), \n",
    "                      control_transformed, alpha=0.6, s=80, label='Control', color='blue')\n",
    "    axes[1, 0].scatter(2 * np.ones(n_sample) + np.random.normal(0, 0.05, n_sample), \n",
    "                      treatment_transformed, alpha=0.6, s=80, label='Mining Site', color='red')\n",
    "    axes[1, 0].hlines(control_transformed.mean(), 0.7, 1.3, colors='blue', linewidth=3)\n",
    "    axes[1, 0].hlines(treatment_transformed.mean(), 1.7, 2.3, colors='red', linewidth=3)\n",
    "    axes[1, 0].set_xlim(0.5, 2.5)\n",
    "    axes[1, 0].set_xticks([1, 2])\n",
    "    axes[1, 0].set_xticklabels(['Control', 'Mining'])\n",
    "    axes[1, 0].set_ylabel(ylabel, fontsize=11)\n",
    "    axes[1, 0].set_title(f'After {transform.upper()} Transform\\n(More symmetric)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 5: Histogram of transformed data\n",
    "    axes[1, 1].hist(control_transformed, bins=20, alpha=0.5, color='blue', \n",
    "                   edgecolor='black', label='Control')\n",
    "    axes[1, 1].hist(treatment_transformed, bins=20, alpha=0.5, color='red', \n",
    "                   edgecolor='black', label='Mining')\n",
    "    axes[1, 1].axvline(control_transformed.mean(), color='blue', linestyle='--', linewidth=2)\n",
    "    axes[1, 1].axvline(treatment_transformed.mean(), color='red', linestyle='--', linewidth=2)\n",
    "    axes[1, 1].set_xlabel(ylabel, fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[1, 1].set_title('Distribution Shape\\n(More NORMAL - better for t-test)', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 6: t-test on transformed data\n",
    "    t_trans, p_trans = stats.ttest_ind(treatment_transformed, control_transformed)\n",
    "    axes[1, 2].axis('off')\n",
    "    result_text_trans = f\"\"\"\n",
    "    T-TEST ON TRANSFORMED DATA\n",
    "    {'='*40}\n",
    "    \n",
    "    Control mean: {control_transformed.mean():.3f}\n",
    "    Mining mean: {treatment_transformed.mean():.3f}\n",
    "    \n",
    "    t-statistic: {t_trans:.3f}\n",
    "    p-value: {p_trans:.4f}\n",
    "    \n",
    "    Decision: {'REJECT' if p_trans < 0.05 else 'FAIL TO REJECT'}\n",
    "    \n",
    "    \u2713 Data is more symmetric\n",
    "    \u2713 t-test assumptions better met\n",
    "    \u2713 p-value is more reliable\n",
    "    \n",
    "    Fold-change: {2**(treatment_transformed.mean() - control_transformed.mean()):.2f}x\n",
    "    \n",
    "    {'='*40}\n",
    "    \"\"\"\n",
    "    color_trans = 'lightgreen' if p_trans < 0.05 else 'lightyellow'\n",
    "    axes[1, 2].text(0.1, 0.5, result_text_trans, fontsize=10, family='monospace',\n",
    "                   verticalalignment='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor=color_trans, alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LESSON: The Shape of Your Data Matters!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nRaw data p-value: {p_raw:.4f}\")\n",
    "    print(f\"Transformed data p-value: {p_trans:.4f}\")\n",
    "    print(f\"\\nDifference in p-values: {abs(p_raw - p_trans):.4f}\")\n",
    "    print(\"\\nWhy transformation helps:\")\n",
    "    print(\"1. Gene expression data is multiplicative (fold-changes)\")\n",
    "    print(\"2. Log transformation converts multiplication to addition\")\n",
    "    print(\"3. Makes the distribution more symmetric (more normal)\")\n",
    "    print(\"4. t-test assumptions are better satisfied\")\n",
    "    print(\"5. Statistical inference becomes more reliable\")\n",
    "    print(\"\\nThis is why bioinformaticians almost always log-transform expression data!\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Example: Gene Expression Analysis\n",
    "\n",
    "**Try different scenarios:**\n",
    "- Increase `fold_change` to see stronger effects\n",
    "- Increase `cv` (coefficient of variation) to add more biological noise\n",
    "- Toggle between 'none' and 'log' transformation to see the difference\n",
    "- Increase sample size to improve power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(gene_expression_example,\n",
    "         n_sample=IntSlider(min=10, max=100, step=10, value=30, description='Sample size:'),\n",
    "         fold_change=FloatSlider(min=1.0, max=5.0, step=0.5, value=2.0, description='Fold change:'),\n",
    "         cv=FloatSlider(min=0.2, max=1.0, step=0.1, value=0.5, description='Variability:'),\n",
    "         transform=Dropdown(options=['none', 'log'], value='log', description='Transform:'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "### The Shape of Uncertainty is Essential for Hypothesis Testing Because:\n",
    "\n",
    "1. **Defines \"Rare\" vs \"Common\"**\n",
    "   - The distribution tells us what outcomes to expect under the null hypothesis\n",
    "   - Without knowing the shape, we can't judge if our observation is unusual\n",
    "\n",
    "2. **Determines Critical Values**\n",
    "   - Different distributions have different tails\n",
    "   - The shape determines where we draw the line between \"accept\" and \"reject\"\n",
    "\n",
    "3. **Affects Statistical Power**\n",
    "   - Narrow distributions (low variance) \u2192 easier to detect effects\n",
    "   - Wide distributions (high variance) \u2192 need larger samples\n",
    "\n",
    "4. **Reveals Assumption Violations**\n",
    "   - If your data shape doesn't match the assumed distribution, p-values are wrong\n",
    "   - This is why we check assumptions (normality, equal variance, etc.)\n",
    "\n",
    "5. **Guides Appropriate Transformations**\n",
    "   - Log-normal data \u2192 log transform\n",
    "   - Count data \u2192 appropriate discrete distributions\n",
    "   - Proportions \u2192 logit transform\n",
    "\n",
    "### Practical Implications for Your Research:\n",
    "\n",
    "- **Always visualize your data first** - look at the shape!\n",
    "- **Check assumptions** - is the distribution appropriate?\n",
    "- **Consider transformations** - especially for gene expression, enzyme activity, or count data\n",
    "- **Sample size matters** - especially with high variability\n",
    "- **Effect size matters** - small effects need larger samples to detect\n",
    "\n",
    "---\n",
    "\n",
    "### Questions for Reflection:\n",
    "\n",
    "1. Why might a significant p-value with raw data become non-significant after transformation (or vice versa)?\n",
    "2. In the coin-flipping example, why does increasing the number of flips make extreme outcomes more detectable?\n",
    "3. For your earthworm research, what kind of transformations might be appropriate for different measurements (weight, length, enzyme activity, gene expression)?\n",
    "4. How would you explain to a non-statistician why we need to check data distribution before running a t-test?\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook was designed for students at Kuchinda College, Department of Zoology.*\n",
    "*For questions or suggestions, contact your instructor.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension Activities\n",
    "\n",
    "### Activity 1: Design Your Own Study\n",
    "Use the interactive widgets above to design a study for detecting earthworm weight differences:\n",
    "- What sample size do you need to detect a 0.5g difference?\n",
    "- How does biological variability affect your power?\n",
    "- What if the effect is only 0.2g - is it detectable?\n",
    "\n",
    "### Activity 2: Real Data Challenge\n",
    "Bring your own data from lab measurements:\n",
    "- Plot histograms to assess the shape\n",
    "- Identify if transformations are needed\n",
    "- Run appropriate tests\n",
    "- Interpret results in biological context\n",
    "\n",
    "### Activity 3: Type I and Type II Errors\n",
    "Modify the code to:\n",
    "- Simulate 1000 experiments with no true effect (mean_diff=0)\n",
    "- Count how many times you reject the null (should be ~5%)\n",
    "- Simulate 1000 experiments with a real effect\n",
    "- Count how many times you correctly detect it (statistical power)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}