{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Hypothesis Testing Fundamentals\n",
    "## Understanding Power, Errors, p-values, and Confidence\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/The-Pattern-Hunter/interactive-ecology-biometry/blob/main/unit-4-biometry/notebooks/06_hypothesis_testing_fundamentals.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "> *\"The p-value is NOT the probability that the null hypothesis is true!\"*\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will deeply understand:\n",
    "1. **What p-values REALLY mean** (and common misconceptions)\n",
    "2. **Significance level (Œ±)** - Why 0.05?\n",
    "3. **Type I and Type II errors** - The two ways to be wrong\n",
    "4. **Statistical Power** - The probability of detecting real effects\n",
    "5. **Confidence Intervals** - What they tell us beyond p-values\n",
    "6. **Degrees of Freedom** - Intuitive understanding\n",
    "7. **Effect Size** - Statistical vs. biological significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install numpy scipy plotly pandas -q\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Ready to deeply understand hypothesis testing!\")\n",
    "print(\"üéØ Let's demystify p-values, power, and errors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 1: What is a p-value? (The Truth!)\n",
    "\n",
    "### ‚ùå Common WRONG Interpretations:\n",
    "\n",
    "1. ‚ùå \"p = 0.03 means there's a 3% chance the null hypothesis is true\"\n",
    "2. ‚ùå \"p = 0.03 means there's a 97% chance the alternative is true\"\n",
    "3. ‚ùå \"p = 0.03 means we've proven the alternative hypothesis\"\n",
    "4. ‚ùå \"p < 0.05 means the result is important\"\n",
    "5. ‚ùå \"p > 0.05 means there's no effect\"\n",
    "\n",
    "### ‚úÖ CORRECT Definition:\n",
    "\n",
    "**p-value = The probability of observing data this extreme (or more extreme) IF the null hypothesis were true.**\n",
    "\n",
    "In other words:\n",
    "> \"If there's truly NO effect, how surprising is our observed data?\"\n",
    "\n",
    "### üé≤ The Courtroom Analogy\n",
    "\n",
    "| Legal System | Statistical Testing |\n",
    "|--------------|---------------------|\n",
    "| **Assumption**: Innocent until proven guilty | **Assumption**: H‚ÇÄ is true until proven otherwise |\n",
    "| **Evidence**: Witness testimony, DNA, etc. | **Evidence**: Your data |\n",
    "| **Verdict**: Guilty or Not Guilty | **Decision**: Reject H‚ÇÄ or Fail to Reject |\n",
    "| **\"Beyond reasonable doubt\"** | **p < 0.05 (conventional threshold)** |\n",
    "| Not guilty ‚â† innocent | Fail to reject ‚â† H‚ÇÄ is true |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Visual Understanding of p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize what p-value represents\n",
    "from scipy import stats as sp_stats\n",
    "\n",
    "# Scenario: Testing if mean plant height = 50cm\n",
    "# H‚ÇÄ: Œº = 50\n",
    "# We observe sample mean = 53cm, with SE = 1.5\n",
    "\n",
    "null_mean = 50\n",
    "observed_mean = 53\n",
    "se = 1.5\n",
    "\n",
    "# Calculate t-statistic\n",
    "t_stat = (observed_mean - null_mean) / se\n",
    "df = 29  # Assume n=30\n",
    "p_value = 2 * (1 - sp_stats.t.cdf(abs(t_stat), df))  # Two-tailed\n",
    "\n",
    "# Create distribution under H‚ÇÄ\n",
    "x = np.linspace(null_mean - 4*se, null_mean + 4*se, 1000)\n",
    "y = sp_stats.t.pdf((x - null_mean)/se, df) / se\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Distribution under H‚ÇÄ\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=y,\n",
    "    mode='lines',\n",
    "    fill='tozeroy',\n",
    "    line=dict(color='lightblue', width=2),\n",
    "    name='Distribution if H‚ÇÄ is true',\n",
    "    fillcolor='rgba(173, 216, 230, 0.3)'\n",
    "))\n",
    "\n",
    "# Shade p-value region (two-tailed)\n",
    "critical_value = null_mean + abs(observed_mean - null_mean)\n",
    "x_right = x[x >= critical_value]\n",
    "y_right = sp_stats.t.pdf((x_right - null_mean)/se, df) / se\n",
    "\n",
    "x_left = x[x <= (null_mean - abs(observed_mean - null_mean))]\n",
    "y_left = sp_stats.t.pdf((x_left - null_mean)/se, df) / se\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_right, y=y_right,\n",
    "    fill='tozeroy',\n",
    "    mode='none',\n",
    "    fillcolor='rgba(255, 0, 0, 0.3)',\n",
    "    name=f'p-value region (p={p_value:.4f})',\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_left, y=y_left,\n",
    "    fill='tozeroy',\n",
    "    mode='none',\n",
    "    fillcolor='rgba(255, 0, 0, 0.3)',\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# Mark observed value\n",
    "fig.add_vline(x=observed_mean, line_dash=\"dash\", line_color=\"red\", line_width=3,\n",
    "              annotation_text=f\"Observed = {observed_mean}cm\")\n",
    "\n",
    "# Mark null hypothesis value\n",
    "fig.add_vline(x=null_mean, line_dash=\"solid\", line_color=\"black\", line_width=2,\n",
    "              annotation_text=f\"H‚ÇÄ: Œº = {null_mean}cm\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"üéØ What p-value Represents<br><sub>If H‚ÇÄ is true (Œº=50), the red shaded areas show how likely we'd see data this extreme</sub>\",\n",
    "    xaxis_title=\"Plant Height (cm)\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nüìä Interpretation:\")\n",
    "print(f\"   Observed sample mean: {observed_mean} cm\")\n",
    "print(f\"   Null hypothesis: Œº = {null_mean} cm\")\n",
    "print(f\"   t-statistic: {t_stat:.2f}\")\n",
    "print(f\"   p-value: {p_value:.4f}\")\n",
    "print(f\"\\nüí° What this means:\")\n",
    "print(f\"   IF the true mean were actually {null_mean}cm,\")\n",
    "print(f\"   we'd see data this extreme (or more) only {p_value*100:.2f}% of the time.\")\n",
    "print(f\"\\n   The red areas = {p_value*100:.2f}% probability\")\n",
    "print(f\"   Since {p_value:.4f} < 0.05, we reject H‚ÇÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéöÔ∏è Part 2: Significance Level (Œ±) - Why 0.05?\n",
    "\n",
    "### What is Œ±?\n",
    "\n",
    "**Œ± (alpha)** = The threshold we set BEFORE seeing data\n",
    "- If p < Œ± ‚Üí Reject H‚ÇÄ\n",
    "- If p ‚â• Œ± ‚Üí Fail to reject H‚ÇÄ\n",
    "\n",
    "### Why 0.05?\n",
    "\n",
    "**Historical Accident!** Ronald Fisher (1920s) suggested it as a convenient cutoff.\n",
    "\n",
    "**It means**: \"We're willing to be wrong 5% of the time when H‚ÇÄ is actually true\"\n",
    "\n",
    "### Different Fields Use Different Œ±:\n",
    "\n",
    "| Field | Common Œ± | Why? |\n",
    "|-------|----------|------|\n",
    "| Ecology, Biology | 0.05 | Historical convention |\n",
    "| Particle Physics | 0.0000003 | Need very high certainty |\n",
    "| Social Sciences | 0.05 or 0.10 | Effects often subtle |\n",
    "| Medical Trials | 0.01 | Patient safety critical |\n",
    "\n",
    "### The Œ± Level Sets Your Threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive comparison of different Œ± levels\n",
    "alpha_levels = [0.10, 0.05, 0.01, 0.001]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Standard normal distribution\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "y = sp_stats.norm.pdf(x)\n",
    "\n",
    "for alpha in alpha_levels:\n",
    "    # Find critical value for two-tailed test\n",
    "    critical_z = sp_stats.norm.ppf(1 - alpha/2)\n",
    "    \n",
    "    # Shade rejection regions\n",
    "    x_reject_right = x[x >= critical_z]\n",
    "    y_reject_right = sp_stats.norm.pdf(x_reject_right)\n",
    "    \n",
    "    x_reject_left = x[x <= -critical_z]\n",
    "    y_reject_left = sp_stats.norm.pdf(x_reject_left)\n",
    "    \n",
    "    visible = (alpha == 0.05)  # Show 0.05 by default\n",
    "    \n",
    "    # Base distribution\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x, y=y,\n",
    "        mode='lines',\n",
    "        line=dict(color='lightblue', width=2),\n",
    "        fill='tozeroy',\n",
    "        fillcolor='rgba(173, 216, 230, 0.3)',\n",
    "        name=f'Œ± = {alpha}',\n",
    "        visible=visible,\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "    # Rejection region\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.concatenate([x_reject_left, x_reject_right]),\n",
    "        y=np.concatenate([y_reject_left, y_reject_right]),\n",
    "        fill='tozeroy',\n",
    "        mode='none',\n",
    "        fillcolor='rgba(255, 0, 0, 0.5)',\n",
    "        name=f'Reject H‚ÇÄ (Œ±={alpha})',\n",
    "        visible=visible\n",
    "    ))\n",
    "\n",
    "# Create buttons\n",
    "buttons = []\n",
    "for i, alpha in enumerate(alpha_levels):\n",
    "    visible = [False] * (len(alpha_levels) * 2)\n",
    "    visible[i*2] = True\n",
    "    visible[i*2 + 1] = True\n",
    "    \n",
    "    critical_z = sp_stats.norm.ppf(1 - alpha/2)\n",
    "    \n",
    "    buttons.append(\n",
    "        dict(\n",
    "            label=f'Œ± = {alpha}',\n",
    "            method='update',\n",
    "            args=[{'visible': visible},\n",
    "                  {'title': f'üéöÔ∏è Significance Level Œ± = {alpha}<br><sub>Red areas = {alpha*100}% total, Critical value = ¬±{critical_z:.2f}</sub>'}]\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[dict(\n",
    "        type='buttons',\n",
    "        direction='down',\n",
    "        x=0.7, y=1.15,\n",
    "        buttons=buttons\n",
    "    )],\n",
    "    title='üéöÔ∏è Significance Level Œ± = 0.05<br><sub>Red areas = 5% total, Critical value = ¬±1.96</sub>',\n",
    "    xaxis_title='z-score',\n",
    "    yaxis_title='Probability Density',\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° Key Points:\")\n",
    "print(\"   ‚Ä¢ Smaller Œ± = More stringent (harder to reject H‚ÇÄ)\")\n",
    "print(\"   ‚Ä¢ Smaller Œ± = Smaller red rejection regions\")\n",
    "print(\"   ‚Ä¢ Œ± = 0.05 means we reject H‚ÇÄ if p < 0.05\")\n",
    "print(\"   ‚Ä¢ Œ± is chosen BEFORE collecting data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Part 3: Type I and Type II Errors\n",
    "\n",
    "### The Four Possible Outcomes\n",
    "\n",
    "When we test a hypothesis, there are 4 possible situations:\n",
    "\n",
    "|  | **H‚ÇÄ is Actually TRUE** | **H‚ÇÄ is Actually FALSE** |\n",
    "|---|------------------------|-------------------------|\n",
    "| **We Reject H‚ÇÄ** | üö® **Type I Error** (Œ±) | ‚úÖ **Correct Decision** (Power) |\n",
    "| **We Fail to Reject H‚ÇÄ** | ‚úÖ **Correct Decision** (1-Œ±) | üö® **Type II Error** (Œ≤) |\n",
    "\n",
    "### Type I Error (False Positive) üö®\n",
    "\n",
    "**Definition**: Rejecting H‚ÇÄ when it's actually true\n",
    "\n",
    "**Probability**: Œ± (significance level)\n",
    "\n",
    "**Example**: \n",
    "- H‚ÇÄ: Fertilizer has no effect\n",
    "- Reality: Fertilizer truly has no effect\n",
    "- Our conclusion: \"Fertilizer works!\" ‚ùå WRONG\n",
    "\n",
    "**Real-world impact**: False discoveries, wasted resources\n",
    "\n",
    "### Type II Error (False Negative) üö®\n",
    "\n",
    "**Definition**: Failing to reject H‚ÇÄ when it's actually false\n",
    "\n",
    "**Probability**: Œ≤ (beta)\n",
    "\n",
    "**Example**:\n",
    "- H‚ÇÄ: Pesticide is safe\n",
    "- Reality: Pesticide is actually harmful\n",
    "- Our conclusion: \"Pesticide is safe\" ‚ùå WRONG\n",
    "\n",
    "**Real-world impact**: Missed discoveries, continued harm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Medical Diagnosis Analogy\n",
    "\n",
    "|  | **Patient is HEALTHY** | **Patient is SICK** |\n",
    "|---|----------------------|--------------------|\n",
    "| **Test says SICK** | Type I Error (False Alarm) | Correct (True Positive) |\n",
    "| **Test says HEALTHY** | Correct (True Negative) | Type II Error (Missed Disease) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Type I and Type II errors\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Two scenarios\n",
    "mu_null = 0  # H‚ÇÄ: mean = 0\n",
    "mu_alt = 2   # H‚ÇÅ: mean = 2 (true effect)\n",
    "sigma = 1\n",
    "alpha = 0.05\n",
    "n = 30\n",
    "se = sigma / np.sqrt(n)\n",
    "\n",
    "# Critical value\n",
    "critical_value = norm.ppf(1 - alpha) * se  # One-tailed for simplicity\n",
    "\n",
    "# Create x values\n",
    "x = np.linspace(-2, 4, 1000)\n",
    "\n",
    "# Distributions\n",
    "y_null = norm.pdf(x, mu_null, se)\n",
    "y_alt = norm.pdf(x, mu_alt, se)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Distribution under H‚ÇÄ\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=y_null,\n",
    "    mode='lines',\n",
    "    line=dict(color='blue', width=2),\n",
    "    fill='tozeroy',\n",
    "    fillcolor='rgba(0, 0, 255, 0.2)',\n",
    "    name='H‚ÇÄ is true (no effect)'\n",
    "))\n",
    "\n",
    "# Type I error region (Œ±)\n",
    "x_type1 = x[x >= critical_value]\n",
    "y_type1 = norm.pdf(x_type1, mu_null, se)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_type1, y=y_type1,\n",
    "    fill='tozeroy',\n",
    "    mode='none',\n",
    "    fillcolor='rgba(255, 0, 0, 0.5)',\n",
    "    name=f'Type I Error (Œ±={alpha})'\n",
    "))\n",
    "\n",
    "# Distribution under H‚ÇÅ\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x, y=y_alt,\n",
    "    mode='lines',\n",
    "    line=dict(color='green', width=2),\n",
    "    fill='tozeroy',\n",
    "    fillcolor='rgba(0, 255, 0, 0.2)',\n",
    "    name='H‚ÇÅ is true (effect exists)'\n",
    "))\n",
    "\n",
    "# Type II error region (Œ≤)\n",
    "x_type2 = x[x < critical_value]\n",
    "y_type2 = norm.pdf(x_type2, mu_alt, se)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_type2, y=y_type2,\n",
    "    fill='tozeroy',\n",
    "    mode='none',\n",
    "    fillcolor='rgba(255, 165, 0, 0.5)',\n",
    "    name='Type II Error (Œ≤)'\n",
    "))\n",
    "\n",
    "# Power region\n",
    "x_power = x[x >= critical_value]\n",
    "y_power = norm.pdf(x_power, mu_alt, se)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_power, y=y_power,\n",
    "    fill='tozeroy',\n",
    "    mode='none',\n",
    "    fillcolor='rgba(0, 128, 0, 0.6)',\n",
    "    name='Power (1-Œ≤)'\n",
    "))\n",
    "\n",
    "# Critical value line\n",
    "fig.add_vline(x=critical_value, line_dash=\"dash\", line_color=\"black\", line_width=3,\n",
    "              annotation_text=f\"Critical value = {critical_value:.2f}\")\n",
    "\n",
    "# Calculate beta and power\n",
    "beta = norm.cdf(critical_value, mu_alt, se)\n",
    "power = 1 - beta\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"‚ö†Ô∏è Type I and Type II Errors<br><sub>Œ±={alpha} (red), Œ≤={beta:.3f} (orange), Power={power:.3f} (dark green)</sub>\",\n",
    "    xaxis_title=\"Test Statistic\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    height=600,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nüìä Error Probabilities:\")\n",
    "print(f\"   Type I Error (Œ±): {alpha*100}% - False positive rate\")\n",
    "print(f\"   Type II Error (Œ≤): {beta*100:.1f}% - False negative rate\")\n",
    "print(f\"   Statistical Power (1-Œ≤): {power*100:.1f}% - True positive rate\")\n",
    "\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   ‚Ä¢ RED (Œ±): If no effect exists, we'll wrongly claim one {alpha*100}% of the time\")\n",
    "print(f\"   ‚Ä¢ ORANGE (Œ≤): If effect exists, we'll miss it {beta*100:.1f}% of the time\")\n",
    "print(f\"   ‚Ä¢ DARK GREEN (Power): If effect exists, we'll detect it {power*100:.1f}% of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trade-off:\n",
    "\n",
    "**You CANNOT eliminate both errors simultaneously!**\n",
    "\n",
    "- ‚¨áÔ∏è Decrease Œ± (be more conservative) ‚Üí ‚¨ÜÔ∏è Increase Œ≤ (more false negatives)\n",
    "- ‚¨ÜÔ∏è Increase Œ± (be less conservative) ‚Üí ‚¨áÔ∏è Decrease Œ≤ (fewer false negatives)\n",
    "\n",
    "**Solution**: Increase sample size! This reduces both errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí™ Part 4: Statistical Power (1 - Œ≤)\n",
    "\n",
    "### What is Power?\n",
    "\n",
    "**Power = The probability of CORRECTLY rejecting H‚ÇÄ when it's actually false**\n",
    "\n",
    "In other words: \"If there's a real effect, what's the chance we'll detect it?\"\n",
    "\n",
    "**Formula**: Power = 1 - Œ≤\n",
    "\n",
    "### What Affects Power?\n",
    "\n",
    "1. **Sample Size (n)** ‚¨ÜÔ∏è n ‚Üí ‚¨ÜÔ∏è Power\n",
    "2. **Effect Size** (how big the difference is) ‚¨ÜÔ∏è Effect ‚Üí ‚¨ÜÔ∏è Power\n",
    "3. **Significance Level (Œ±)** ‚¨ÜÔ∏è Œ± ‚Üí ‚¨ÜÔ∏è Power (but more Type I errors)\n",
    "4. **Variability (œÉ)** ‚¨áÔ∏è œÉ ‚Üí ‚¨ÜÔ∏è Power\n",
    "\n",
    "### Recommended Power:\n",
    "\n",
    "**Convention: Power ‚â• 0.80 (80%)**\n",
    "\n",
    "This means: \"If there's a real effect, we have at least 80% chance of detecting it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive power analysis - Effect of sample size\n",
    "effect_size = 0.5  # Cohen's d\n",
    "alpha = 0.05\n",
    "sample_sizes = np.arange(10, 201, 10)\n",
    "\n",
    "powers = []\n",
    "for n in sample_sizes:\n",
    "    # Calculate power using t-distribution\n",
    "    ncp = effect_size * np.sqrt(n)  # non-centrality parameter\n",
    "    critical_t = sp_stats.t.ppf(1 - alpha/2, n-1)\n",
    "    power = 1 - sp_stats.nct.cdf(critical_t, n-1, ncp) + sp_stats.nct.cdf(-critical_t, n-1, ncp)\n",
    "    powers.append(power)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=sample_sizes,\n",
    "    y=powers,\n",
    "    mode='lines+markers',\n",
    "    line=dict(color='green', width=3),\n",
    "    marker=dict(size=8),\n",
    "    name='Statistical Power'\n",
    "))\n",
    "\n",
    "# Add 80% power line\n",
    "fig.add_hline(y=0.80, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=\"Recommended Power = 0.80\")\n",
    "\n",
    "# Find n for 80% power\n",
    "n_for_80 = sample_sizes[np.argmin(np.abs(np.array(powers) - 0.80))]\n",
    "fig.add_vline(x=n_for_80, line_dash=\"dot\", line_color=\"blue\",\n",
    "              annotation_text=f\"n ‚âà {n_for_80} needed\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"üí™ Power Analysis: Effect of Sample Size<br><sub>Effect size (Cohen's d) = {effect_size}, Œ± = {alpha}</sub>\",\n",
    "    xaxis_title=\"Sample Size (n)\",\n",
    "    yaxis_title=\"Statistical Power (1 - Œ≤)\",\n",
    "    height=500,\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(range=[0, 1])\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nüìä Power Analysis Results:\")\n",
    "print(f\"   To achieve 80% power with effect size d={effect_size}:\")\n",
    "print(f\"   You need approximately n={n_for_80} samples per group\")\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "print(f\"   ‚Ä¢ Small samples (n<30) have low power (<50%)\")\n",
    "print(f\"   ‚Ä¢ Power increases rapidly at first, then plateaus\")\n",
    "print(f\"   ‚Ä¢ Doubling n doesn't double power\")\n",
    "print(f\"   ‚Ä¢ Always do power analysis BEFORE collecting data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive power analysis - Effect of effect size\n",
    "n = 30  # Fixed sample size\n",
    "effect_sizes = np.linspace(0.1, 2.0, 50)\n",
    "alpha = 0.05\n",
    "\n",
    "powers_by_effect = []\n",
    "for d in effect_sizes:\n",
    "    ncp = d * np.sqrt(n)\n",
    "    critical_t = sp_stats.t.ppf(1 - alpha/2, n-1)\n",
    "    power = 1 - sp_stats.nct.cdf(critical_t, n-1, ncp) + sp_stats.nct.cdf(-critical_t, n-1, ncp)\n",
    "    powers_by_effect.append(power)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=effect_sizes,\n",
    "    y=powers_by_effect,\n",
    "    mode='lines',\n",
    "    line=dict(color='purple', width=3),\n",
    "    fill='tozeroy',\n",
    "    fillcolor='rgba(128, 0, 128, 0.2)'\n",
    "))\n",
    "\n",
    "# Add reference lines for Cohen's d categories\n",
    "fig.add_vline(x=0.2, line_dash=\"dot\", line_color=\"gray\", annotation_text=\"Small (d=0.2)\")\n",
    "fig.add_vline(x=0.5, line_dash=\"dot\", line_color=\"gray\", annotation_text=\"Medium (d=0.5)\")\n",
    "fig.add_vline(x=0.8, line_dash=\"dot\", line_color=\"gray\", annotation_text=\"Large (d=0.8)\")\n",
    "\n",
    "fig.add_hline(y=0.80, line_dash=\"dash\", line_color=\"red\",\n",
    "              annotation_text=\"80% Power\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"üí™ Power vs Effect Size<br><sub>Sample size n={n}, Œ±={alpha}</sub>\",\n",
    "    xaxis_title=\"Effect Size (Cohen's d)\",\n",
    "    yaxis_title=\"Statistical Power\",\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° Cohen's d Effect Size Guidelines:\")\n",
    "print(\"   ‚Ä¢ Small: d = 0.2 (subtle difference)\")\n",
    "print(\"   ‚Ä¢ Medium: d = 0.5 (moderate difference)\")\n",
    "print(\"   ‚Ä¢ Large: d = 0.8 (obvious difference)\")\n",
    "print(f\"\\n   With n={n} samples:\")\n",
    "small_idx = np.argmin(np.abs(effect_sizes - 0.2))\n",
    "med_idx = np.argmin(np.abs(effect_sizes - 0.5))\n",
    "large_idx = np.argmin(np.abs(effect_sizes - 0.8))\n",
    "print(f\"   ‚Ä¢ Small effect (d=0.2): Power = {powers_by_effect[small_idx]:.1%}\")\n",
    "print(f\"   ‚Ä¢ Medium effect (d=0.5): Power = {powers_by_effect[med_idx]:.1%}\")\n",
    "print(f\"   ‚Ä¢ Large effect (d=0.8): Power = {powers_by_effect[large_idx]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìè Part 5: Confidence Intervals - Beyond p-values\n",
    "\n",
    "### What is a Confidence Interval?\n",
    "\n",
    "**Definition**: A range of plausible values for the population parameter\n",
    "\n",
    "**95% CI = A range that would contain the true parameter in 95% of repeated experiments**\n",
    "\n",
    "### ‚ùå Common WRONG Interpretations:\n",
    "\n",
    "1. ‚ùå \"There's a 95% probability the true value is in this interval\"\n",
    "2. ‚ùå \"95% of the data falls in this interval\"\n",
    "\n",
    "### ‚úÖ CORRECT Interpretation:\n",
    "\n",
    "\"If we repeated this study 100 times, about 95 of the resulting confidence intervals would contain the true population parameter.\"\n",
    "\n",
    "### Why CIs are Better Than p-values:\n",
    "\n",
    "1. **Show magnitude of effect** (not just significance)\n",
    "2. **Show precision** (width indicates uncertainty)\n",
    "3. **Give range of plausible values**\n",
    "4. **More informative than binary yes/no**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate confidence intervals\n",
    "np.random.seed(42)\n",
    "\n",
    "# True population\n",
    "true_mean = 50\n",
    "true_sd = 10\n",
    "n_samples = 30\n",
    "\n",
    "# Take 20 different samples and calculate CIs\n",
    "n_experiments = 20\n",
    "cis = []\n",
    "sample_means = []\n",
    "\n",
    "for i in range(n_experiments):\n",
    "    sample = np.random.normal(true_mean, true_sd, n_samples)\n",
    "    mean = np.mean(sample)\n",
    "    se = np.std(sample, ddof=1) / np.sqrt(n_samples)\n",
    "    \n",
    "    # 95% CI\n",
    "    ci_lower = mean - 1.96 * se\n",
    "    ci_upper = mean + 1.96 * se\n",
    "    \n",
    "    contains_true = (ci_lower <= true_mean <= ci_upper)\n",
    "    \n",
    "    cis.append((ci_lower, ci_upper, contains_true))\n",
    "    sample_means.append(mean)\n",
    "\n",
    "# Plot\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, (ci_lower, ci_upper, contains) in enumerate(cis):\n",
    "    color = 'blue' if contains else 'red'\n",
    "    \n",
    "    # CI line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[ci_lower, ci_upper],\n",
    "        y=[i, i],\n",
    "        mode='lines',\n",
    "        line=dict(color=color, width=2),\n",
    "        showlegend=False,\n",
    "        hovertemplate=f'Experiment {i+1}<br>CI: [{ci_lower:.1f}, {ci_upper:.1f}]<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Sample mean\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[sample_means[i]],\n",
    "        y=[i],\n",
    "        mode='markers',\n",
    "        marker=dict(color=color, size=10, symbol='circle'),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "# True mean line\n",
    "fig.add_vline(x=true_mean, line_dash=\"dash\", line_color=\"black\", line_width=3,\n",
    "              annotation_text=f\"True Mean = {true_mean}\")\n",
    "\n",
    "n_contain = sum(c[2] for c in cis)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"üìè 20 Different Experiments, Each with 95% Confidence Interval<br><sub>{n_contain}/20 ({n_contain/20*100:.0f}%) intervals contain the true mean</sub>\",\n",
    "    xaxis_title=\"Value\",\n",
    "    yaxis_title=\"Experiment Number\",\n",
    "    height=600,\n",
    "    template='plotly_white',\n",
    "    yaxis=dict(range=[-1, n_experiments])\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nüìä Results:\")\n",
    "print(f\"   True population mean: {true_mean}\")\n",
    "print(f\"   Number of experiments: {n_experiments}\")\n",
    "print(f\"   CIs containing true mean: {n_contain}/{n_experiments} ({n_contain/20*100:.0f}%)\")\n",
    "print(f\"   CIs missing true mean (RED): {n_experiments-n_contain}\")\n",
    "print(f\"\\nüí° This is what '95% confidence' means:\")\n",
    "print(f\"   In the long run, about 95% of CIs will contain the true parameter\")\n",
    "print(f\"   Any single CI either contains it (100%) or doesn't (0%) - we just don't know which!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CI Width Tells Us About Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CI width with different sample sizes\n",
    "true_mean = 50\n",
    "true_sd = 10\n",
    "sample_sizes = [10, 30, 100, 300]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, n in enumerate(sample_sizes):\n",
    "    sample = np.random.normal(true_mean, true_sd, n)\n",
    "    mean = np.mean(sample)\n",
    "    se = true_sd / np.sqrt(n)  # Using known SD for comparison\n",
    "    \n",
    "    ci_lower = mean - 1.96 * se\n",
    "    ci_upper = mean + 1.96 * se\n",
    "    ci_width = ci_upper - ci_lower\n",
    "    \n",
    "    # Draw CI\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[ci_lower, ci_upper],\n",
    "        y=[i, i],\n",
    "        mode='lines',\n",
    "        line=dict(color='blue', width=4),\n",
    "        name=f'n={n} (width={ci_width:.1f})'\n",
    "    ))\n",
    "    \n",
    "    # Mean point\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[mean],\n",
    "        y=[i],\n",
    "        mode='markers',\n",
    "        marker=dict(color='red', size=12),\n",
    "        showlegend=False,\n",
    "        hovertemplate=f'n={n}<br>Mean={mean:.2f}<br>CI: [{ci_lower:.2f}, {ci_upper:.2f}]<extra></extra>'\n",
    "    ))\n",
    "\n",
    "fig.add_vline(x=true_mean, line_dash=\"dash\", line_color=\"black\",\n",
    "              annotation_text=\"True Mean\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üìè Confidence Interval Width vs Sample Size<br><sub>Larger n = Narrower CI = More Precision</sub>\",\n",
    "    xaxis_title=\"Value\",\n",
    "    yaxis=dict(ticktext=[f'n={n}' for n in sample_sizes],\n",
    "               tickvals=list(range(len(sample_sizes)))),\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   ‚Ä¢ Larger sample size ‚Üí Narrower CI ‚Üí More precision\")\n",
    "print(\"   ‚Ä¢ Narrow CI = We know the true value more precisely\")\n",
    "print(\"   ‚Ä¢ Wide CI = More uncertainty about true value\")\n",
    "print(\"   ‚Ä¢ CI width decreases proportional to 1/‚àön\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¢ Part 6: Degrees of Freedom (df) - Intuitive Understanding\n",
    "\n",
    "### What Are Degrees of Freedom?\n",
    "\n",
    "**Simple Definition**: The number of values that are free to vary after we impose certain constraints.\n",
    "\n",
    "### The Ice Cream Analogy:\n",
    "\n",
    "Imagine you have 5 scoops of ice cream to distribute among 5 friends, and the average must be exactly 1 scoop per person:\n",
    "\n",
    "- Friend 1: You can choose ANY amount (0, 2, 3, etc.) ‚úÖ FREE\n",
    "- Friend 2: You can choose ANY amount ‚úÖ FREE\n",
    "- Friend 3: You can choose ANY amount ‚úÖ FREE\n",
    "- Friend 4: You can choose ANY amount ‚úÖ FREE\n",
    "- Friend 5: You MUST take whatever's left ‚ùå NOT FREE\n",
    "\n",
    "**Degrees of Freedom = 5 - 1 = 4**\n",
    "\n",
    "Once you know 4 values and the mean, the 5th value is determined!\n",
    "\n",
    "### Why \"n - 1\" for Sample Standard Deviation?\n",
    "\n",
    "When calculating sample SD:\n",
    "1. We use the sample mean (xÃÑ) - this is a CONSTRAINT\n",
    "2. Once we know (n-1) deviations from xÃÑ, the last one is determined\n",
    "3. Therefore: df = n - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate degrees of freedom with constraints\n",
    "n = 5\n",
    "target_mean = 10\n",
    "target_sum = n * target_mean  # = 50\n",
    "\n",
    "print(\"üç¶ The Ice Cream Distribution Example:\")\n",
    "print(f\"   You have {n} scoops to distribute among {n} friends\")\n",
    "print(f\"   Constraint: Average must be exactly {target_mean} scoops\")\n",
    "print(f\"   Total sum must be: {target_sum} scoops\\n\")\n",
    "\n",
    "# Choose values for first 4 friends\n",
    "values = np.array([8, 12, 15, 7])  # First 4 values (chosen freely)\n",
    "sum_so_far = np.sum(values)\n",
    "last_value = target_sum - sum_so_far  # 5th value is DETERMINED\n",
    "\n",
    "print(\"   Friend 1: 8 scoops ‚úÖ (your choice)\")\n",
    "print(\"   Friend 2: 12 scoops ‚úÖ (your choice)\")\n",
    "print(\"   Friend 3: 15 scoops ‚úÖ (your choice)\")\n",
    "print(\"   Friend 4: 7 scoops ‚úÖ (your choice)\")\n",
    "print(f\"   Friend 5: {last_value} scoops ‚ùå (MUST be this value!)\")\n",
    "\n",
    "all_values = np.append(values, last_value)\n",
    "actual_mean = np.mean(all_values)\n",
    "\n",
    "print(f\"\\n   Check: Mean = {actual_mean} ‚úÖ\")\n",
    "print(f\"   Degrees of Freedom: n - 1 = {n} - 1 = {n-1}\")\n",
    "print(f\"\\nüí° Once you know {n-1} values and the mean, the last value is determined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Does df Matter?\n",
    "\n",
    "**Different df ‚Üí Different t-distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how t-distribution changes with df\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "df_values = [1, 3, 10, 30, 100]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Standard normal (infinite df)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=sp_stats.norm.pdf(x),\n",
    "    mode='lines',\n",
    "    line=dict(color='black', width=3, dash='dash'),\n",
    "    name='Normal (df=‚àû)'\n",
    "))\n",
    "\n",
    "colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "for df, color in zip(df_values, colors):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x,\n",
    "        y=sp_stats.t.pdf(x, df),\n",
    "        mode='lines',\n",
    "        line=dict(color=color, width=2),\n",
    "        name=f't-distribution (df={df})'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üî¢ t-Distribution vs Degrees of Freedom<br><sub>As df increases, t-distribution approaches Normal</sub>\",\n",
    "    xaxis_title=\"Value\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° Key Observations:\")\n",
    "print(\"   ‚Ä¢ Low df (small n): Fatter tails, more spread out\")\n",
    "print(\"   ‚Ä¢ High df (large n): Approaches Normal distribution\")\n",
    "print(\"   ‚Ä¢ df=30+: Practically identical to Normal\")\n",
    "print(\"   ‚Ä¢ Lower df ‚Üí Need larger t-value to be significant\")\n",
    "\n",
    "# Show critical values\n",
    "print(\"\\nüìä Critical t-values for p=0.05 (two-tailed):\")\n",
    "for df in [5, 10, 30, 100]:\n",
    "    crit = sp_stats.t.ppf(0.975, df)\n",
    "    print(f\"   df={df:3}: t_crit = {crit:.3f}\")\n",
    "print(f\"   Normal:  z_crit = {sp_stats.norm.ppf(0.975):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common df in Different Tests:\n",
    "\n",
    "| Test | Degrees of Freedom |\n",
    "|------|-------------------|\n",
    "| **One-sample t-test** | df = n - 1 |\n",
    "| **Independent t-test** | df = n‚ÇÅ + n‚ÇÇ - 2 |\n",
    "| **Paired t-test** | df = n - 1 (n = number of pairs) |\n",
    "| **Chi-square** | df = (rows - 1) √ó (columns - 1) |\n",
    "| **ANOVA** | df_between = k - 1, df_within = N - k |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 7: Effect Size - Statistical vs Biological Significance\n",
    "\n",
    "### The Problem with p-values Alone:\n",
    "\n",
    "**p-value depends on sample size!**\n",
    "\n",
    "With large enough n:\n",
    "- Even TINY differences become \"statistically significant\" (p < 0.05)\n",
    "- But they might be biologically meaningless!\n",
    "\n",
    "### Example: Height Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate: tiny effect, large n ‚Üí significant p-value\n",
    "np.random.seed(42)\n",
    "\n",
    "# Two groups with TINY difference\n",
    "group1_mean = 170.0  # cm\n",
    "group2_mean = 170.5  # cm (only 5mm difference!)\n",
    "sd = 10\n",
    "\n",
    "sample_sizes = [10, 50, 100, 500, 1000]\n",
    "results = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    group1 = np.random.normal(group1_mean, sd, n)\n",
    "    group2 = np.random.normal(group2_mean, sd, n)\n",
    "    \n",
    "    t_stat, p_val = sp_stats.ttest_ind(group1, group2)\n",
    "    \n",
    "    # Calculate Cohen's d\n",
    "    pooled_sd = np.sqrt((np.var(group1, ddof=1) + np.var(group2, ddof=1)) / 2)\n",
    "    cohens_d = (np.mean(group2) - np.mean(group1)) / pooled_sd\n",
    "    \n",
    "    results.append({\n",
    "        'n': n,\n",
    "        'p_value': p_val,\n",
    "        'cohens_d': cohens_d,\n",
    "        'significant': 'Yes*' if p_val < 0.05 else 'No'\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(\"üéØ Same Effect Size, Different Sample Sizes:\\n\")\n",
    "print(f\"   True difference: {group2_mean - group1_mean} cm (only 5mm!)\\n\")\n",
    "print(\"Sample Size | p-value  | Cohen's d | Significant?\")\n",
    "print(\"------------|----------|-----------|-------------\")\n",
    "for _, row in df_results.iterrows():\n",
    "    print(f\"   n={row['n']:4}   | {row['p_value']:8.4f} |   {row['cohens_d']:5.3f}   |    {row['significant']}\")\n",
    "\n",
    "print(\"\\nüí° Key Lesson:\")\n",
    "print(\"   ‚Ä¢ With n=1000, we get p<0.05 (statistically significant)\")\n",
    "print(\"   ‚Ä¢ But the actual difference is only 5mm (0.3% of height)\")\n",
    "print(\"   ‚Ä¢ Cohen's d ‚âà 0.05 (trivial effect size)\")\n",
    "print(\"   ‚Ä¢ Statistically significant ‚â† Biologically important!\")\n",
    "\n",
    "# Visualize\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('p-value vs Sample Size', \"Cohen's d (Effect Size)\"))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results['n'],\n",
    "    y=df_results['p_value'],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=10, color='blue'),\n",
    "    name='p-value'\n",
    "), row=1, col=1)\n",
    "\n",
    "fig.add_hline(y=0.05, line_dash=\"dash\", line_color=\"red\", row=1, col=1,\n",
    "              annotation_text=\"Œ±=0.05\")\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_results['n'],\n",
    "    y=df_results['cohens_d'],\n",
    "    mode='lines+markers',\n",
    "    marker=dict(size=10, color='green'),\n",
    "    name=\"Cohen's d\"\n",
    "), row=1, col=2)\n",
    "\n",
    "fig.add_hline(y=0.2, line_dash=\"dot\", line_color=\"gray\", row=1, col=2,\n",
    "              annotation_text=\"Small effect\")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Sample Size\", type=\"log\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Sample Size\", type=\"log\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"p-value\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Cohen's d\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=400, template='plotly_white', showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's d Effect Size Guidelines:\n",
    "\n",
    "| Cohen's d | Interpretation | Example |\n",
    "|-----------|----------------|----------|\n",
    "| d < 0.2 | **Trivial** | Barely noticeable |\n",
    "| d = 0.2 | **Small** | Subtle but detectable |\n",
    "| d = 0.5 | **Medium** | Clearly noticeable |\n",
    "| d = 0.8 | **Large** | Obvious difference |\n",
    "| d > 1.2 | **Very Large** | Dramatic difference |\n",
    "\n",
    "### The Right Approach:\n",
    "\n",
    "**Always report BOTH:**\n",
    "1. ‚úÖ **Statistical significance** (p-value)\n",
    "2. ‚úÖ **Effect size** (Cohen's d, confidence interval)\n",
    "3. ‚úÖ **Biological significance** (does it matter in practice?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Summary: The Complete Picture\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "#### 1. **p-value**\n",
    "‚úÖ = Probability of data this extreme IF H‚ÇÄ is true  \n",
    "‚ùå ‚â† Probability that H‚ÇÄ is true  \n",
    "‚ùå ‚â† Proof that H‚ÇÅ is true  \n",
    "\n",
    "#### 2. **Significance Level (Œ±)**\n",
    "- Chosen BEFORE data collection\n",
    "- Convention: Œ± = 0.05\n",
    "- = Acceptable Type I error rate\n",
    "\n",
    "#### 3. **Type I Error (Œ±)**\n",
    "- False positive\n",
    "- Rejecting true H‚ÇÄ\n",
    "- \"Crying wolf\"\n",
    "\n",
    "#### 4. **Type II Error (Œ≤)**\n",
    "- False negative\n",
    "- Failing to reject false H‚ÇÄ\n",
    "- \"Missing the signal\"\n",
    "\n",
    "#### 5. **Statistical Power (1-Œ≤)**\n",
    "- Probability of detecting real effects\n",
    "- Aim for ‚â• 80%\n",
    "- Increases with: larger n, larger effect, higher Œ±\n",
    "\n",
    "#### 6. **Confidence Intervals**\n",
    "- Range of plausible values\n",
    "- Shows magnitude + precision\n",
    "- More informative than p-values alone\n",
    "\n",
    "#### 7. **Degrees of Freedom**\n",
    "- Number of independent values\n",
    "- = n - (number of constraints)\n",
    "- Affects critical values\n",
    "\n",
    "#### 8. **Effect Size**\n",
    "- Magnitude of difference\n",
    "- Independent of sample size\n",
    "- Cohen's d: 0.2=small, 0.5=medium, 0.8=large\n",
    "\n",
    "### The Golden Rules:\n",
    "\n",
    "1. ‚úÖ **Set Œ± before collecting data**\n",
    "2. ‚úÖ **Do power analysis before study**\n",
    "3. ‚úÖ **Report effect sizes AND p-values**\n",
    "4. ‚úÖ **Report confidence intervals**\n",
    "5. ‚úÖ **Consider biological significance**\n",
    "6. ‚ùå **Never p-hack** (don't try multiple tests until significant)\n",
    "7. ‚ùå **Never cherry-pick** (report all tests, not just significant ones)\n",
    "8. ‚ùå **Never confuse** statistical with biological significance\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Recommended Next Steps:\n",
    "\n",
    "1. Review Notebook 05 (Hypothesis Testing Applications)\n",
    "2. Practice with real datasets\n",
    "3. Always calculate effect sizes\n",
    "4. Always report confidence intervals\n",
    "5. Think critically about biological meaning\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "**Made with üíö by The Pattern Hunter Team**\n",
    "\n",
    "**üéâ You now understand hypothesis testing at a deep level! üéâ**\n",
    "\n",
    "[üè† Repository](https://github.com/The-Pattern-Hunter/interactive-ecology-biometry) | \n",
    "[üìì Previous: Hypothesis Testing](05_hypothesis_testing.ipynb) | \n",
    "[ü©∫ Unit 4 Home](../../)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}